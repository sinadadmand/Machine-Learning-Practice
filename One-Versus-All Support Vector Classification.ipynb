{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASC521: Homework 2\n",
    "## Sina Dadmand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and dividing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv('hw06_images.csv', header = None)\n",
    "labels = pd.read_csv('hw06_labels.csv', header = None)\n",
    "\n",
    "train = images.loc[:999,]\n",
    "test = images.loc[1000:,]\n",
    "\n",
    "train_y = labels.loc[:999, 0]\n",
    "test_y = labels.loc[1000:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimations for the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of classes and number of samples\n",
    "K = int(np.max(labels))\n",
    "N = train.shape[0]\n",
    "\n",
    "\n",
    "# define Gaussian kernel function\n",
    "def gaussian_kernel(X1, X2, s):\n",
    "    D = dt.cdist(X1, X2)\n",
    "    K = np.exp(-D**2 / (2 * s**2))\n",
    "    return(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score function for Bayes classifier and max score finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny = 1e-308 # for the safelog\n",
    "\n",
    "# Naive-Bayes \n",
    "def bayes(x, mean, dev, prior):\n",
    "    P = (1/(dev * np.sqrt(2 * np.pi))) * np.exp(((mean - x)*(x - mean))/(2 * dev * dev))\n",
    "    P = np.log(P+tiny)\n",
    "    return np.sum(P) + np.log(prior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.empty(shape=(len(train_y),))\n",
    "\n",
    "for i in range(len(train_y)):\n",
    "    train_pred[i] = np.argmax(np.array([bayes(train.loc[i,:], sample_means[0], sample_deviations[0], class_priors[0]), \n",
    "                                          bayes(train.loc[i,:], sample_means[1], sample_deviations[1], class_priors[1]),\n",
    "                                          bayes(train.loc[i,:], sample_means[2], sample_deviations[2], class_priors[2]),\n",
    "                                          bayes(train.loc[i,:], sample_means[3], sample_deviations[3], class_priors[3]),\n",
    "                                          bayes(train.loc[i,:], sample_means[4], sample_deviations[4], class_priors[4]),\n",
    "                                         ])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.empty(shape=(len(test_y),))\n",
    "\n",
    "for i in range(len(test_y)):\n",
    "    test_pred[i] = np.argmax(np.array([bayes(test.loc[N+i,:], sample_means[0], sample_deviations[0], class_priors[0]), \n",
    "                                         bayes(test.loc[N+i,:], sample_means[1], sample_deviations[1], class_priors[1]),\n",
    "                                         bayes(test.loc[N+i,:], sample_means[2], sample_deviations[2], class_priors[2]),\n",
    "                                         bayes(test.loc[N+i,:], sample_means[3], sample_deviations[3], class_priors[3]),\n",
    "                                         bayes(test.loc[N+i,:], sample_means[4], sample_deviations[4], class_priors[4]),\n",
    "                                         ])) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_truth     1     2     3     4     5\n",
      "y_pred                               \n",
      "1.0      3685    49     4   679     6\n",
      "2.0      1430  5667  1140  1380   532\n",
      "3.0       508   208  4670  2948   893\n",
      "4.0       233    59   123   686   180\n",
      "5.0       144    17    63   307  4389\n",
      "y_truth    1    2    3    4    5\n",
      "y_pred                          \n",
      "1.0      597    6    0  114    1\n",
      "2.0      237  955  188  267   81\n",
      "3.0       92   25  785  462  167\n",
      "4.0       34   11   16  109   29\n",
      "5.0       40    3   11   48  722\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train = pd.crosstab(train_pred, train_y, rownames = ['y_pred'], colnames = ['y_truth'])\n",
    "confusion_matrix_test = pd.crosstab(test_pred, test_y, rownames = ['y_pred'], colnames = ['y_truth'])\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
